{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find My Son"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries and set mode(Local or GLab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xkogi\\.conda\\envs\\myenv\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_alt.xml\n",
      "03m02s300ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#mode:'local' means on local machine, 'glabo' means on google colab \n",
    "mode = 'local'\n",
    "#mode = 'glabo'\n",
    "\n",
    "if mode =='glabo':\n",
    "    ROOT_DIR='/content/gdrive/My Drive/opencv'\n",
    "    cascade_path = '/./usr/local/lib/python3.6/dist-packages/cv2/data/'\n",
    "    OUT_DIR = os.path.join('./')\n",
    "elif mode:\n",
    "    ROOT_DIR='./'\n",
    "    cascade_path=\"C:\\\\Users\\\\xkogi\\\\.conda\\\\envs\\\\myenv\\\\Lib\\\\site-packages\\\\cv2\\\\data\\\\\"\n",
    "    OUT_DIR = os.path.join('./','output')\n",
    "    \n",
    "# alias\n",
    "scale_factor=1.1 #default = 1.1\n",
    "min_size = (5,5)\n",
    "min_neighbour=3 #default=3\n",
    "(resize_width, resize_height) = (130, 100)\n",
    "\n",
    "MOV_FULL_L='gassou_full_large.mp4'\n",
    "MOV_FULL_S='gassou_full_small.mp4'\n",
    "MOV_LONG_L ='gassou_30sec_large.mp4'\n",
    "MOV_LONG_S ='gassou_30sec_small.mp4'\n",
    "MOV_SHORT_L = 'gassou_15sec_large.mp4'\n",
    "MOV_SHORT_S = 'gassou_15sec_small.mp4'\n",
    "IMG_REPORT = 'img_report.jpg'\n",
    "IMG_INTEVIEW = 'img_interviewMovie.jpg'\n",
    "\n",
    "# movie file\n",
    "def getImageFile(name=''):\n",
    "    path = os.path.join(ROOT_DIR,name)\n",
    "    if os.path.exists(os.path.join(path)):\n",
    "        return path\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# get haar cascade file\n",
    "def getcascade(name='frontalface_alt2'):\n",
    "    if name == 'eye':\n",
    "        return os.path.join(cascade_path,'haarcascade_eye.xml')\n",
    "    elif name == 'eye_tree_eyeglasses':\n",
    "        return os.path.join(cascade_path,'haarcascade_eye_tree_eyeglasses.xml')\n",
    "    elif name == 'frontalcatface':\n",
    "        return os.path.join(cascade_path,'haarcascade_frontalcatface.xml')\n",
    "    elif name == 'frontalcatface_extended':\n",
    "        return os.path.join(cascade_path,'haarcascade_frontalcatface_extended.xml')\n",
    "    elif name == 'frontalface_alt':\n",
    "        return os.path.join(cascade_path,'haarcascade_frontalface_alt.xml')\n",
    "    elif name == 'frontalface_alt2':\n",
    "        return os.path.join(cascade_path,'haarcascade_frontalface_alt2.xml')\n",
    "    elif name == 'frontalface_alt_tree':\n",
    "        return os.path.join(cascade_path,'haarcascade_frontalface_alt_tree.xml')\n",
    "    elif name == 'frontalface_default':\n",
    "        return os.path.join(cascade_path,'haarcascade_frontalface_default.xml')\n",
    "    elif name == 'fullbody':\n",
    "        return os.path.join(cascade_path,'haarcascade_fullbody.xml')\n",
    "    elif name == 'lefteye_2splits':\n",
    "        return os.path.join(cascade_path,'haarcascade_lefteye_2splits.xml')\n",
    "    elif name == 'licence_plate_rus_16stages':\n",
    "        return os.path.join(cascade_path,'haarcascade_licence_plate_rus_16stages.xml')\n",
    "    elif name == 'lowerbody':\n",
    "        return os.path.join(cascade_path,'haarcascade_lowerbody.xml')\n",
    "    elif name == 'profileface':\n",
    "        return os.path.join(cascade_path,'haarcascade_profileface.xml')\n",
    "    elif name == 'righteye_2splits':\n",
    "        return os.path.join(cascade_path,'haarcascade_righteye_2splits.xml')\n",
    "    elif name == 'russian_plate_number':\n",
    "        return os.path.join(cascade_path,'haarcascade_russian_plate_number.xml')\n",
    "    elif name == 'smile':\n",
    "        return os.path.join(cascade_path,'haarcascade_smile.xml')\n",
    "    elif name == 'upperbody':\n",
    "        return os.path.join(cascade_path,'haarcascade_upperbody.xml')\n",
    "    else:\n",
    "        return os.path.join(cascade_path,'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "# format time(second) as HH:MM:ss.mmm\n",
    "def format_time(sec):\n",
    "    msec = (int)(sec * 1000.)\n",
    "    s, ms = divmod(msec, 1000)\n",
    "    m, s =divmod(s,60)\n",
    "    return '{:02d}:{:02d}.{:03d}'.format(m,s,ms)\n",
    "\n",
    "def format_time_forfile(sec):\n",
    "    msec = (int)(sec * 1000.)\n",
    "    s, ms = divmod(msec, 1000)\n",
    "    m, s =divmod(s,60)\n",
    "    return '{:02d}m{:02d}s{:03d}ms'.format(m,s,ms)\n",
    "\n",
    "print(getcascade('frontalface_alt'))\n",
    "print(format_time_forfile(182.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps 23.976023976023978\n",
      "interval:  0.04170833333333333 time_wait:  41\n"
     ]
    }
   ],
   "source": [
    "# create capture and get params\n",
    "def getCapture(movie,cascade=''):\n",
    "    cap = cv2.VideoCapture(getImageFile(movie))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    face_cascade=cv2.CascadeClassifier(getcascade(cascade))\n",
    "    print('fps',fps)\n",
    "    return cap,width,height,fps,face_cascade\n",
    "\n",
    "def getInterval(fps):\n",
    "    interval =1.0/fps\n",
    "    time_wait = (int)(interval * 1000.0)\n",
    "    print('interval: ',interval,'time_wait: ',time_wait)\n",
    "    return interval,time_wait\n",
    "\n",
    "# detect face from movie and show it on screen\n",
    "def face_detect_mov(movie,cascade):\n",
    "    cap,width,height,fps,face_cascade = getCapture(movie,cascade)\n",
    "    interval,time_wait = getInterval(fps)\n",
    "    ret, frame = cap.read()\n",
    "    FLAG_FACE = True\n",
    "    time_stamp=0.0\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    while(1):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            if FLAG_FACE == True:\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                faces = face_cascade.detectMultiScale(gray, scaleFactor=scale_factor, minNeighbors=min_neighbour, minSize=min_size) # , 1.3, 5)\n",
    "                #img = np.zeros((width,height,3), np.uint8)\n",
    "                for(x, y, w, h) in faces:\n",
    "                    frame = cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "                    #img[x:x+w,y:y+h]=frame[x:x+h,y:y+h]\n",
    "            time_stamp = time_stamp + interval\n",
    "            cv2.putText(frame,format_time(time_stamp),(10,50),font,4,(255,255,255),2,cv2.LINE_AA)\n",
    "            cv2.imshow('frame',frame)\n",
    "            k = cv2.waitKey(time_wait) & 0xff\n",
    "            if k == 27:\n",
    "                break;\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    \n",
    "face_detect_mov(MOV_LONG_S,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps 23.976023976023978\n",
      "interval:  0.04170833333333333 time_wait:  41\n"
     ]
    }
   ],
   "source": [
    "# detect facce from movie, write rectangle and save as movie\n",
    "# this is not complete, I don't want run here, so just changed as a function\n",
    "def face_detect_mov_save(movie,output,cascade=''):\n",
    "    cap,width,height,fps,face_cascade = getCapture(movie,cascade)\n",
    "    interval,time_wait = getInterval(fps)\n",
    "\n",
    "    time_stamp=0.0\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "    # VideoWriter を作成する。\n",
    "    if mode == 'glabo':\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "    else:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    writer = cv2.VideoWriter(os.path.join(OUT_DIR,output), fourcc, fps, (width, height))\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, scaleFactor=scale_factor, minNeighbors=min_neighbour, minSize=min_size) # , 1.3, 5)\n",
    "            for(x, y, w, h) in faces:\n",
    "                frame = cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "            time_stamp = time_stamp + interval\n",
    "            cv2.putText(frame,format_time(time_stamp),(10,50),font,4,(255,255,255),2,cv2.LINE_AA)\n",
    "            writer.write(frame)\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    cap.release()\n",
    "    writer.release()\n",
    "#face_detect_mov_save(MOV_LONG_S,'out_move_long.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition\n",
    "* see [https://github.com/informramiz/opencv-face-recognition-python](https://github.com/informramiz/opencv-face-recognition-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to detect face using openCV\n",
    "subjects = [\"\",\"Son\",\"boy\",\"girl\",\"suzu\",'shishamo','family']\n",
    "def detect_face(img):\n",
    "    #convert the test image to gray image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # load OpenCV face detector\n",
    "    face_cascade =cv2.CascadeClassifier(getcascade(''))\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=scale_factor, minNeighbors=min_neighbour, minSize=min_size) # , 1.3, 5)\n",
    "\n",
    "    if(len(faces) == 0):\n",
    "        return None, None\n",
    "    \n",
    "    (x,y,w,h) = faces[0]\n",
    "    \n",
    "    return gray[y:y+w, x:x+h], faces[0]\n",
    "    \n",
    "# prepare training data\n",
    "# this function will read all persons training images, detect face from each image\n",
    "# and will return two lists of exactly same size,\n",
    "# one list of face and another list of labels for each face\n",
    "def prepare_training_data(data_folder_path):\n",
    "    # ---step 1---\n",
    "    # get the directories (one directory for each subject) in data folder\n",
    "    dirs = os.listdir(data_folder_path)\n",
    "    \n",
    "    # list to hold all subject faces\n",
    "    faces = []\n",
    "    # list to hold labels for all subjects\n",
    "    labels = []\n",
    "    \n",
    "    # let's go through each directory and read images within it\n",
    "    for dir_name in dirs:\n",
    "        # our subjcect directories start with letter 's' so ignore any non-relevant directoies if any\n",
    "        if not dir_name.startswith(\"s\"):\n",
    "            continue\n",
    "        print('dir: ',dir_name)\n",
    "        # --step 2---\n",
    "        # extract label number of subjet from dir_name\n",
    "        # format of dir name = slabel\n",
    "        label = int(dir_name.replace(\"s\",\"\"))\n",
    "        \n",
    "        # build path of directory containing image for current subject\n",
    "        # sample subject_dir_path = \"training-data/s1\"\n",
    "        subject_dir_path =os.path.join(data_folder_path,dir_name)\n",
    "        \n",
    "        # get the images names that are inside the given subject directory\n",
    "        subject_images_names = os.listdir(subject_dir_path)\n",
    "        \n",
    "        # ---step 3---\n",
    "        # go through each image name, read image,\n",
    "        # detect face and add face to list of faces\n",
    "        for image_name in subject_images_names:\n",
    "            # ignore system files like .DS_Store\n",
    "            if image_name.startswith(\".\"):\n",
    "                continue\n",
    "                \n",
    "            # build image path\n",
    "            image_path = os.path.join(subject_dir_path,image_name)\n",
    "            \n",
    "            # read image\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            #display an image window to show the image\n",
    "            cv2.imshow(\"training on image...\",image)\n",
    "            cv2.waitKey(100)\n",
    "            \n",
    "            # detect face\n",
    "            face, rect = detect_face(image)\n",
    "            \n",
    "            # ---step 4---\n",
    "            # for the purpose of this, we will ignore faces that are not detected\n",
    "            if face is not None:\n",
    "                #print(image_name,'detect')\n",
    "                # add face to list of faces\n",
    "                face_resize = cv2.resize(face, (resize_width,resize_height))\n",
    "                cv2.imshow(\"training on image...\",face_resize)\n",
    "                faces.append(face_resize)\n",
    "                cv2.waitKey(200)\n",
    "                # add label for this face\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                print(image_name,'face not detected.')\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "        \n",
    "    return faces, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing data...\n",
      "dir:  s1\n",
      "dir:  s2\n",
      "dir:  s3\n",
      "dir:  s4\n",
      "dir:  s5\n",
      "dir:  s6\n",
      "data prepared\n",
      "Total faces:  74\n",
      "Total labels;  74\n"
     ]
    }
   ],
   "source": [
    "print(\"preparing data...\")\n",
    "faces, labels = prepare_training_data(\"training-data\")\n",
    "print(\"data prepared\")\n",
    "\n",
    "print(\"Total faces: \", len(faces))\n",
    "print(\"Total labels; \",len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./training-data/s6/7.jpg not exits.\n"
     ]
    }
   ],
   "source": [
    "file_name='./training-data/s6/7.jpg'\n",
    "# file_name='../image-collector-master/shishamo/23.jpg'\n",
    "if os.path.exists(file_name):\n",
    "    img=cv2.imread(file_name)\n",
    "    face,rect=detect_face(img)\n",
    "    if face is not None:\n",
    "        (x,y,w,h)=rect\n",
    "        img = cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    cv2.imshow('test',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "else:\n",
    "    print(file_name,'not exits.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create face recognizer\n",
    "#face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "#face_recognizer = cv2.face.createLBPHFaceRecognizer()\n",
    "face_recognizer = cv2.face_LBPHFaceRecognizer.create()\n",
    "#or use EigenFaceRecognizer by replacing above line with \n",
    "#face_recognizer = cv2.face.createEigenFaceRecognizer()\n",
    "#face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "\n",
    "#or use FisherFaceRecognizer by replacing above line with \n",
    "#face_recognizer = cv2.face.FisherFaceRecognizer_create()\n",
    "(width, height) = (130, 100)\n",
    "\n",
    "# train face recognizer\n",
    "face_recognizer.train(faces,np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(img, rect):\n",
    "    (x, y, w, h) = rect\n",
    "    cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "    \n",
    "def draw_text(img, text, x, y):\n",
    "    cv2.putText(img, text, (x,y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0,255,0), 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recognize!\n",
    "def predict(test_image):\n",
    "    img = test_img.copy()\n",
    "    face, rect = detect_face(img)\n",
    "    \n",
    "    #prediction\n",
    "    face_resize = cv2.resize(face, (resize_width, resize_height))\n",
    "    label = face_recognizer.predict(face_resize)\n",
    "    print(label)\n",
    "    label_text = subjects[label[0]]\n",
    "    \n",
    "    draw_rectangle(img, rect)\n",
    "    draw_text(img, label_text, rect[0], rect[1]-5)\n",
    "    return img\n",
    "\n",
    "def predict_son_only(test_image,face_cascade):\n",
    "    img = test_image.copy()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=scale_factor, minNeighbors=min_neighbour, minSize=min_size) # , 1.3, 5)\n",
    "    found = False\n",
    "    for(x, y, w, h) in faces:\n",
    "        face = gray[y:y+w, x:x+h]\n",
    "        rect = (x,y,w,h)\n",
    "        face_resize = cv2.resize(face, (width, height))\n",
    "        label = face_recognizer.predict(face_resize)\n",
    "        if label[0] == 1:\n",
    "            print(subjects[label[0]],label)\n",
    "            label_text = subjects[label[0]] #+'('+str(label[1])+')'\n",
    "            found = True\n",
    "            draw_rectangle(img, rect)\n",
    "            draw_text(img, label_text, rect[0], rect[1]-5)\n",
    "    return found,img\n",
    "\n",
    "def predictall(test_image,face_cascade,disp=False):\n",
    "    img = test_image.copy()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "      # load OpenCV face detector\n",
    "#    face_cascade =cv2.CascadeClassifier(getcascade(''))\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=scale_factor, minNeighbors=min_neighbour, minSize=min_size) # , 1.3, 5)\n",
    "    found = False\n",
    "    for(x, y, w, h) in faces:\n",
    "        face = gray[y:y+w, x:x+h]\n",
    "        rect = (x,y,w,h)\n",
    "        draw_rectangle(img, rect)\n",
    "        face_resize = cv2.resize(face, (width, height))\n",
    "        label = face_recognizer.predict(face_resize)\n",
    "        if disp:\n",
    "            print(subjects[label[0]],label)\n",
    "        if label[1] < 500:\n",
    "            label_text = subjects[label[0]] #+'('+str(label[1])+')'\n",
    "            found = found or label[0] == 1\n",
    "            draw_text(img, label_text, rect[0], rect[1]-5)\n",
    "    return found,img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "girl (3, 102.77895658475059)\n",
      "boy (2, 103.07513575520454)\n",
      "family (6, 100.27964613958467)\n",
      "Son (1, 111.10979660731897)\n",
      "family (6, 87.11710511905338)\n",
      "boy (2, 94.97964196463933)\n",
      "Son (1, 102.647247632844)\n",
      "family (6, 99.82292955329477)\n",
      "girl (3, 88.8998334025174)\n",
      "boy (2, 108.10849404729298)\n",
      "found!\n"
     ]
    }
   ],
   "source": [
    "test_img = cv2.imread(\"./test-data/12.jpg\")\n",
    "face_cascade =cv2.CascadeClassifier(getcascade(''))\n",
    "found,predict_img = predictall(test_img,face_cascade,True)\n",
    "#found,predict_img = predict_son_only(test_img,face_cascade)\n",
    "if found:\n",
    "    print(\"found!\")\n",
    "cv2.imshow(\"test\",predict_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps 23.976023976023978\n",
      "interval:  0.04170833333333333 time_wait:  41\n",
      "1 found at: 00:00.166\n",
      "2 found at: 00:00.208\n",
      "3 found at: 00:00.250\n",
      "4 found at: 00:00.291\n",
      "5 found at: 00:00.333\n",
      "6 found at: 00:00.375\n",
      "7 found at: 00:00.917\n",
      "8 found at: 00:01.001\n",
      "9 found at: 00:01.126\n",
      "10 found at: 00:01.376\n",
      "11 found at: 00:01.626\n",
      "12 found at: 00:01.876\n",
      "13 found at: 00:02.085\n",
      "14 found at: 00:02.210\n",
      "15 found at: 00:02.585\n",
      "16 found at: 00:02.627\n",
      "17 found at: 00:02.669\n",
      "18 found at: 00:02.711\n",
      "19 found at: 00:02.794\n",
      "20 found at: 00:02.836\n",
      "21 found at: 00:02.877\n",
      "22 found at: 00:03.294\n",
      "23 found at: 00:06.297\n",
      "24 found at: 00:06.423\n"
     ]
    }
   ],
   "source": [
    "# face recognize on movie\n",
    "def face_recognize_mov(movie,outpath=None,cascade='',disp=True):\n",
    "    cap,width,height,fps,face_cascade = getCapture(movie,cascade)\n",
    "    interval,time_wait = getInterval(fps)\n",
    "    time_stamp=0.0\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    counter = 0\n",
    "    while(1):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            found,frame = predictall(frame,face_cascade)\n",
    "            time_stamp = time_stamp + interval\n",
    "            strTime = format_time(time_stamp)\n",
    "            cv2.putText(frame,strTime,(10,50),font,4,(255,255,255),2,cv2.LINE_AA)\n",
    "            if disp:\n",
    "                cv2.imshow('frame',frame)\n",
    "            if found:\n",
    "                counter = counter + 1\n",
    "                print(str(counter),'found at:',strTime)\n",
    "                if outpath is not None:\n",
    "                    filename=os.path.join(outpath,format_time_forfile(time_stamp)+'.png')\n",
    "                    cv2.imwrite(filename,frame)\n",
    "            if disp:\n",
    "                k = cv2.waitKey(time_wait) & 0xff\n",
    "                if k == 27:\n",
    "                    break;\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "face_recognize_mov(MOV_FULL_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
