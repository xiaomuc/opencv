{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# face detection using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import functions as fn\n",
    "import webcolors\n",
    "\n",
    "sys.path.append(\"./\")\n",
    "sys.path.append(\"./utils/\")\n",
    "sys.path.append(\"./protos/\")\n",
    "import label_map_util\n",
    "import visualization_utils_color as vis_util\n",
    "\n",
    "disp_height=1080/1.55\n",
    "disp_width=1920/1.55\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    %matplotlib inline\n",
    "    from google.colab import drive\n",
    "    from google.colab.patches import cv2_imshow\n",
    "    drive.mount('/content/gdrive')\n",
    "    DRIVE_ROOT='/content/gdrive/My Drive/opencv/'\n",
    "    !pip install face_recognition\n",
    "except:\n",
    "    IN_COLAB =False\n",
    "    %matplotlib notebook  \n",
    "    DRIVE_ROOT='./'\n",
    "PATH_TO_CKPT = os.path.join(DRIVE_ROOT,'model/frozen_inference_graph_face.pb')\n",
    "PATH_TO_LABELS = os.path.join(DRIVE_ROOT,'protos/face_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map,max_num_classes=NUM_CLASSES,use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "    (im_width,im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape((im_height,im_width, 3)).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asako', 'Aya', 'ClassMate1', 'ClassMate2', 'Girl1', 'Jiro', 'Saki', 'Suzu', 'Toma']\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "known_face_names = []\n",
    "known_face_encodings = []\n",
    "\n",
    "def scan_known_faces(known_people_folder):\n",
    "    image_files_in_folder = os.listdir(known_people_folder)\n",
    "    for name in image_files_in_folder:\n",
    "        if name.startswith(\".\"):\n",
    "            continue\n",
    "        file=os.path.join(known_people_folder,name)\n",
    "        basename = os.path.splitext(os.path.basename(file))[0]\n",
    "        img = face_recognition.load_image_file(file)\n",
    "        encodings = face_recognition.face_encodings(img)\n",
    "\n",
    "        if len(encodings) > 1:\n",
    "            click.echo(\"WARNING: More than one face found in {}. Only considering the first face.\".format(file))\n",
    "\n",
    "        if len(encodings) == 0:\n",
    "            click.echo(\"WARNING: No faces found in {}. Ignoring file.\".format(file))\n",
    "        else:\n",
    "            known_face_names.append(basename)\n",
    "            known_face_encodings.append(encodings[0])\n",
    "\n",
    "    return known_face_names, known_face_encodings\n",
    "\n",
    "scan_known_faces('./known_face/')            \n",
    "print(known_face_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "font_scale = 1.2\n",
    "thickness = 2\n",
    "\n",
    "def calc_resize(image,size=None):\n",
    "    if size is None:\n",
    "        im_height,im_width = image.shape[:2]\n",
    "    else:\n",
    "        (im_width,im_height) = size\n",
    "    print('w',im_width,'h',im_height)\n",
    "    if im_height>disp_height or im_width>disp_width:\n",
    "        ratio =min(disp_height/im_height,disp_width/im_width)\n",
    "        print('r',ratio)\n",
    "        im_height=int(im_height*ratio)\n",
    "        im_width=int(im_width*ratio)\n",
    "    else:\n",
    "        ratio=1\n",
    "    print('w',im_width,'h',im_height)\n",
    "    return (im_width,im_height),ratio\n",
    "\n",
    "def recognize(image,face_locations,threshold=0.6):\n",
    "    face_names=[]\n",
    "    frame = image[:,:,::-1]\n",
    "    face_encodings = face_recognition.face_encodings(image,face_locations)\n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_face_encodings,face_encoding)\n",
    "        name = 'unknown'\n",
    "        \n",
    "        face_distance = face_recognition.face_distance(known_face_encodings,face_encoding)\n",
    "        best_match_index = np.argmin(face_distance)\n",
    "        if matches[best_match_index]:\n",
    "            if face_distance[best_match_index]<threshold:\n",
    "                name = known_face_names[best_match_index]\n",
    "            else:\n",
    "                name = '?'+known_face_names[best_match_index]+'?'\n",
    "        face_names.append(name)\n",
    "    return face_names\n",
    "\n",
    "def name_to_bgr(name):\n",
    "    (r,g,b)=webcolors.name_to_rgb(name)\n",
    "    return (b,g,r)\n",
    "\n",
    "def get_detection_graph():\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "        with tf.gfile.GFile(PATH_TO_CKPT,'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "    return detection_graph\n",
    "\n",
    "def boxes_to_face_locations(boxes,scores,image_height,image_width,threshold=0.7):\n",
    "    # print('threshold',threshold,'boxes',len(boxes))\n",
    "    face_locations=[]\n",
    "    for i in range(len(boxes)):\n",
    "        if scores[i]>threshold:\n",
    "            #print(i,scores[i])\n",
    "            ymin,xmin,ymax,xmax = boxes[i]\n",
    "            top = int(image_height*ymin)\n",
    "            left=int(image_width*xmin)\n",
    "            bottom=int(image_height*ymax)\n",
    "            right=int(image_width*xmax)\n",
    "            face_locations.append((top,right,bottom,left))\n",
    "            #(top,right,bottom,left)=face_location;\n",
    "    #print('face_locations',len(face_locations))\n",
    "    return face_locations\n",
    "\n",
    "def resize_showimage(in_image,face_locations,face_names,size=None,ratio=None):\n",
    "    if ratio is None or size is None:\n",
    "        size,ratio = calc_resize(image)\n",
    "    print(size,ratio)\n",
    "    image=cv2.resize(in_image,size)\n",
    "    b_bgr=name_to_bgr('blue')\n",
    "    w_bgr=name_to_bgr('white')\n",
    "    r_bgr=name_to_bgr('red')\n",
    "    for i in range(len(face_locations)):\n",
    "        face_location=face_locations[i]\n",
    "        (top,right,bottom,left)=face_location;\n",
    "        top = int(top*ratio)\n",
    "        right=int(right*ratio)\n",
    "        bottom=int(bottom*ratio)\n",
    "        left=int(left*ratio)\n",
    "        name=face_names[i]\n",
    "        if name == 'Toma':\n",
    "            col=r_bgr\n",
    "        else:\n",
    "            col=b_bgr\n",
    "        image=cv2.resize(image,size)\n",
    "        cv2.rectangle(image, (left,top), (right,bottom), col,thickness)\n",
    "        text_size = cv2.getTextSize(name, font, font_scale, thickness)\n",
    "        text_width = text_size[0][0]\n",
    "        text_height = text_size[0][1]\n",
    "        \n",
    "        cv2.rectangle(image, (left, bottom), (left+text_width+thickness, bottom+text_height+thickness), col, cv2.FILLED)\n",
    "        cv2.putText(image, name, (left,bottom + text_height), font,font_scale, w_bgr, thickness)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def detect(image,detection_graph,sess):\n",
    "    image_np = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "    image_np_expanded = np.expand_dims(image_np,axis=0)\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            \n",
    "    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "    start_time = time.time()\n",
    "    (boxes, scores, classes, num_detections) = sess.run(\n",
    "        [boxes,scores,classes,num_detections],\n",
    "        feed_dict={image_tensor: image_np_expanded}\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('inteference time cost: {}'.format(elapsed_time))\n",
    "    boxes=np.squeeze(boxes)\n",
    "    scores=np.squeeze(scores)\n",
    "    classes=np.squeeze(classes)\n",
    "    im_height,im_width = image.shape[:2]\n",
    "            \n",
    "    face_locations = boxes_to_face_locations(boxes,scores,im_height,im_width)\n",
    "    #face_names=recognize(image,face_locations)\n",
    "    #image=resize_showimage(image,face_locations,face_names)\n",
    "    return face_locations\n",
    "\n",
    "\n",
    "def detect_face_tf(image):\n",
    "    detection_graph=get_detection_graph()\n",
    "    with detection_graph.as_default():\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        with tf.Session(graph=detection_graph, config=config) as sess:\n",
    "            #image_np = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            #image_np_expanded = np.expand_dims(image_np,axis=0)\n",
    "            #image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            \n",
    "            #boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            #scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            #classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            #num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            #start_time = time.time()\n",
    "            #(boxes, scores, classes, num_detections) = sess.run(\n",
    "            #    [boxes,scores,classes,num_detections],\n",
    "            #    feed_dict={image_tensor: image_np_expanded}\n",
    "            #)\n",
    "            #elapsed_time = time.time() - start_time\n",
    "            #print('inteference time cost: {}'.format(elapsed_time))\n",
    "            #boxes=np.squeeze(boxes)\n",
    "            #scores=np.squeeze(scores)\n",
    "            #classes=np.squeeze(classes)\n",
    "            #im_height,im_width = image.shape[:2]\n",
    "            \n",
    "            #face_locations = boxes_to_face_locations(boxes,scores,im_height,im_width)\n",
    "            face_locations = detect(image,detection_graph,sess)\n",
    "            face_names=recognize(image,face_locations)\n",
    "            image=resize_showimage(image,face_locations,face_names)\n",
    "            return image\n",
    "\n",
    "#file_name=\"./test-data/img_report.jpg\"\n",
    "#file_name=\"./test-data/IMG_5710.JPG\" # k family\n",
    "#file_name=\"./test-data/12.jpg\" # N family\n",
    "file_name=\"./test-data/IMG_4523.JPG\" # family\n",
    "image = cv2.imread(file_name)\n",
    "image=detect_face_tf(image)\n",
    "\n",
    "#sz,ratio = calc_resize(image)\n",
    "#image=cv2.resize(image,sz)\n",
    "cv2.imshow(\"test\",image)\n",
    "\n",
    "image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "cv2.waitKey(0) & 0xFF\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_movie(video_file,output_file=None):\n",
    "    # input\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    interval,time_wait = fn.getInterval(fps)\n",
    "    show_size,show_ratio = calc_resize(None,(video_width,video_height))\n",
    "\n",
    "    # output\n",
    "    if output is not None:\n",
    "        if IN_COLAB:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "        else:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "        writer = cv2.VideoWriter(os.path.join(OUT_DIR,output), fourcc, fps, (width, height))\n",
    "    else:\n",
    "        writer = None\n",
    "\n",
    "    # ready for tensorflow\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "        with tf.gfile.GFile(PATH_TO_CKPT,'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "        \n",
    "    with detection_graph.as_default():\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        with tf.Session(graph=detection_graph, config=config) as sess:\n",
    "            while cap.isOpened():\n",
    "                ret,frame = cap.read()\n",
    "                if not ret:\n",
    "                    cap.release()\n",
    "                    break\n",
    "                face_locations = detect(frame,detection_graph,sess)\n",
    "                face_names=recognize(frame,face_locations)\n",
    "                if writer is not None:\n",
    "                    write_image=resize_showimage(frame,face_locations,face_names,(video_width,video_height),1.0)\n",
    "                    writer.write(write_image)\n",
    "\n",
    "\n",
    "            cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the original source from web\n",
    "def origin_proc():\n",
    "    cap = cv2.VideoCapture('./gassou_30sec_large.mp4')\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    interval,time_wait = fn.getInterval(fps)\n",
    "    out = None\n",
    "    print('w:',width,'h:',height)\n",
    "\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "        with tf.gfile.GFile(PATH_TO_CKPT,'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "        \n",
    "    with detection_graph.as_default():\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        with tf.Session(graph=detection_graph, config=config) as sess:\n",
    "            frame_num = 1490\n",
    "            while frame_num:\n",
    "                frame_num-=1\n",
    "                ret, image = cap.read()\n",
    "                if ret == 0:\n",
    "                    break\n",
    "                if out is None:\n",
    "                    #[h,w] = image.shape[:2]\n",
    "                    fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "                    #out = cv2.VideoWriter(\"./media/test_out.avi\", 0,25.0, (w,h))\n",
    "                    out = cv2.VideoWriter(\"./media/test_out.avi\", fourcc, fps, (width, height))\n",
    "\n",
    "                image_np = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "                image_np_expanded = np.expand_dims(image_np,axis=0)\n",
    "                image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            \n",
    "                boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            \n",
    "                scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "                classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "                num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            \n",
    "                start_time = time.time()\n",
    "                (boxes, scores, classes, num_detections) = sess.run(\n",
    "                    [boxes,scores,classes,num_detections],\n",
    "                    feed_dict={image_tensor: image_np_expanded}\n",
    "                )\n",
    "                elapsed_time = time.time() - start_time\n",
    "                #print('inteference time cost: {}'.format(elapsed_time))\n",
    "            \n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                    image,\n",
    "                    np.squeeze(boxes),\n",
    "                    np.squeeze(classes).astype(np.int32),\n",
    "                    np.squeeze(scores),\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    line_thickness=2\n",
    "                )\n",
    "                out.write(image)\n",
    "                image=cv2.resize(image,(960,540))\n",
    "                cv2.imshow(\"detect_by_tensorflow\",image)\n",
    "                k=cv2.waitKey(time_wait) & 0xFF\n",
    "                if k==27:\n",
    "                    break;\n",
    "\n",
    "            cv2.destroyAllWindows()\n",
    "            cap.release()\n",
    "            out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
