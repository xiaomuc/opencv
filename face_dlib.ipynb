{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "colab_type": "code",
    "id": "1CLVHn-gKIS1",
    "outputId": "b4a8748c-f5ab-478f-a6c3-3a1466dd8f15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
      "Requirement already satisfied: face_recognition in /usr/local/lib/python3.6/dist-packages (1.2.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.16.4)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (4.3.0)\n",
      "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.16.0)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->face_recognition) (0.46)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    %matplotlib inline\n",
    "    from google.colab import drive\n",
    "    from google.colab.patches import cv2_imshow\n",
    "    drive.mount('/content/gdrive')\n",
    "    DRIVE_ROOT='/content/gdrive/My Drive/opencv/'\n",
    "    !pip install face_recognition\n",
    "except:\n",
    "    IN_COLAB =False\n",
    "    %matplotlib notebook  \n",
    "    DRIVE_ROOT='./'\n",
    "\n",
    "import face_recognition\n",
    "face_dir = os.path.join(DRIVE_ROOT,'known_face')\n",
    "OUT_DIR =os.path.join(DRIVE_ROOT,'output')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "HYW6MZJ4KIS9",
    "outputId": "92e37141-4ff4-42e2-ca0a-ac5704c24ac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asako\n",
      "ClassMate1\n",
      "Girl1\n",
      "ClassMate2\n",
      "Suzu\n",
      "Toma\n"
     ]
    }
   ],
   "source": [
    "known_face_encodings=[]\n",
    "known_face_names=[]\n",
    "subject_image_names=os.listdir(face_dir)\n",
    "for image_name in subject_image_names:\n",
    "    if image_name.startswith(\".\"):\n",
    "        continue\n",
    "    name=os.path.splitext(image_name)[0];\n",
    "    image_path = os.path.join(face_dir,image_name)\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    face_encoding = face_recognition.face_encodings(image)[0]\n",
    "    known_face_encodings.append(face_encoding)\n",
    "    known_face_names.append(name)\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r6mlusOZKITC"
   },
   "outputs": [],
   "source": [
    "# single frame recognition\n",
    "def recognize_face(frame,do_scale=False,threshold=0.5,debug=False):\n",
    "    face_locations=[]\n",
    "    face_encodings=[]\n",
    "    face_names=[]\n",
    "    \n",
    "    if do_scale:\n",
    "        # resize frame to 1/4 size for faster processing\n",
    "        small_frame = cv2.resize(frame, (0,0), fx=0.25, fy=0.25)\n",
    "    else:\n",
    "        small_frame = frame\n",
    "    result=False   \n",
    "    # convert the image from BGR color to RGB color\n",
    "    rgb_small_frame = small_frame[:,:,::-1]\n",
    "    \n",
    "    # find all the faces and face encodings in the frame\n",
    "    face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "    #if debug:\n",
    "        #print(face_locations)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_small_frame,face_locations)\n",
    "    result=False\n",
    "    for face_encoding in face_encodings:\n",
    "        # see if the face is a match for the known face(s)\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        name = 'Unknown'\n",
    "        \n",
    "        # use the known face with the smallest distance\n",
    "        face_distance = face_recognition.face_distance(known_face_encodings,face_encoding)\n",
    "        best_match_index = np.argmin(face_distance)\n",
    "        if matches[best_match_index]:\n",
    "            if face_distance[best_match_index]<threshold:\n",
    "                name = known_face_names[best_match_index]\n",
    "            else:\n",
    "                name = '?'+known_face_names[best_match_index]+'?'\n",
    "            if debug:\n",
    "                print(name,face_distance)\n",
    "        if name == 'Toma':\n",
    "            result=True\n",
    "        face_names.append(name)\n",
    "    \n",
    "    #display result\n",
    "    for(top,right,bottom,left),name in zip(face_locations,face_names):\n",
    "        #scale back up face locations since the frame detected in was scaled to 1/4 size\n",
    "        if do_scale:\n",
    "            top *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "        \n",
    "        #draw a box around the face\n",
    "        cv2.rectangle(frame, (left,top), (right,bottom), (0,0,255),2)\n",
    "        \n",
    "        # draw a label with a name below the face\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        font_scale = 1.2\n",
    "        thickness = 2\n",
    "        margin=1\n",
    "        \n",
    "        size = cv2.getTextSize(name, font, font_scale, thickness)\n",
    "        text_width = size[0][0]\n",
    "        text_height = size[0][1]\n",
    "        \n",
    "        cv2.rectangle(frame, (left, bottom), (left+text_width+margin, bottom+text_height+margin), (0, 0, 255), cv2.FILLED)\n",
    "        cv2.putText(frame, name, (left,bottom + text_height), font,font_scale, (255,255,255), thickness)\n",
    "    return result,frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MEsmxpESKITF"
   },
   "outputs": [],
   "source": [
    "# detect face locations        \n",
    "def detect_face_locations(image,do_gray=False,do_scale=False,large_frame=False):\n",
    "    print('detect_face_locations',large_frame)\n",
    "    if do_scale:\n",
    "        small_frame = cv2.resize(image, (0,0), fx=0.25, fy=0.25)\n",
    "    else:\n",
    "        small_frame = image\n",
    "    if do_gray:\n",
    "        gray = cv2.cvtColor(small_frame,cv2.COLOR_BGR2RGB)\n",
    "        rgb_frame = gray[:,:,::-1]\n",
    "    else:\n",
    "        rgb_frame=small_frame[:,:,::-1]\n",
    "\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    for face_location in face_locations:\n",
    "        (top,right,bottom,left)=face_location;\n",
    "        if do_scale:\n",
    "            top *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "\n",
    "        cv2.rectangle(image, (left,top), (right,bottom), (0,0,255),2)\n",
    "        if large_frame:\n",
    "            height, width = image.shape[:2]\n",
    "            frame_width=int((right-left)/2)\n",
    "            frame_height=int((bottom-top)/2)\n",
    "            top=max(0,top-frame_height)\n",
    "            bottom=min(bottom+frame_height,height)\n",
    "            left=max(0,left-frame_width)\n",
    "            right=min(right+frame_width,width)\n",
    "            print(top,left,bottom,right)\n",
    "            cv2.rectangle(image, (left,top), (right,bottom), (0,255,255),2)\n",
    "        #plt.plot(face_location[1],face_location[0],'bo')\n",
    "        #plt.plot(face_location[1],face_location[2],'bo')\n",
    "        #plt.plot(face_location[3],face_location[2],'bo')\n",
    "        #plt.plot(face_location[3],face_location[0],'bo')\n",
    "        #plt.show()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c7ENVknWKITI"
   },
   "outputs": [],
   "source": [
    "# test functions\n",
    "# format time(second) as HH:MM:ss.mmm\n",
    "def format_time(sec):\n",
    "    msec = (int)(sec * 1000.)\n",
    "    s, ms = divmod(msec, 1000)\n",
    "    m, s =divmod(s,60)\n",
    "    return '{:02d}:{:02d}.{:03d}'.format(m,s,ms)\n",
    "\n",
    "def format_time_forfile(sec):\n",
    "    msec = (int)(sec * 1000.)\n",
    "    s, ms = divmod(msec, 1000)\n",
    "    m, s =divmod(s,60)\n",
    "    return '{:02d}m{:02d}s{:03d}ms'.format(m,s,ms)\n",
    "\n",
    "# single image\n",
    "def single_image(filename,detect_only=False,debug=False,large_frame=False):\n",
    "#image=cv2.imread(\"img_interviewMovie.jpg\")\n",
    "    if debug:\n",
    "        print('single image :',filename,'detect only:',detect_only,'large_frame:',large_frame)\n",
    "    image=cv2.imread(filename)\n",
    "    if detect_only:\n",
    "        image=detect_face_locations(image,large_frame=large_frame)\n",
    "    else:\n",
    "        ret,image=recognize_face(image,debug=debug)\n",
    "    if IN_COLAB:\n",
    "      cv2_imshow(image)\n",
    "    else:\n",
    "      cv2.imshow(\"sigle test\",image)\n",
    "      if cv2.waitKey(0) & 0xFF:\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "def getInterval(fps):\n",
    "    interval =1.0/fps\n",
    "    time_wait = (int)(interval * 1000.0)\n",
    "    print('interval: ',interval,'time_wait: ',time_wait)\n",
    "    return interval,time_wait\n",
    "\n",
    "def video_proc(filename,output=None,capture=False,detect_only=False,no_wait=False,view=True):\n",
    "    pre = os.path.splitext(os.path.basename(filename))[0]\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    interval,time_wait = getInterval(fps)\n",
    "    time_stamp=0.0\n",
    "    frame_count=0\n",
    "    if no_wait:\n",
    "        time_wait=1\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    font_scale = 1.2\n",
    "    thickness = 2\n",
    "    margin=1\n",
    "    size = cv2.getTextSize(name, font, font_scale, thickness)\n",
    "    text_width = size[0][0]\n",
    "    text_height = size[0][1]\n",
    "    counter = 0\n",
    "    \n",
    "    # VideoWriter を作成する。\n",
    "    if output is not None:\n",
    "        if IN_COLAB:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "        else:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "        writer = cv2.VideoWriter(os.path.join(OUT_DIR,output), fourcc, fps, (width, height))\n",
    "    else:\n",
    "        writer = None\n",
    "        \n",
    "    if capture:\n",
    "      CAPTURE_DIR=os.path.join(OUT_DIR,pre)\n",
    "      os.makedirs(CAPTURE_DIR,exist_ok=True)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "        if not ret:\n",
    "            cap.release()\n",
    "            break\n",
    "        frame_count += 1\n",
    "        if detect_only:\n",
    "            frame=detect_face_locations(frame)\n",
    "        else:\n",
    "            result,frame=recognize_face(frame)\n",
    "        cv2.putText(frame,format_time(time_stamp),(margin,margin+text_height),font,font_scale,(0,0,255),thickness)\n",
    "        if result:\n",
    "            counter += 1\n",
    "            print(str(counter),format_time(time_stamp))\n",
    "            if capture:\n",
    "                out_name=os.path.join(CAPTURE_DIR,pre+'_'+format_time_forfile(time_stamp)+'.png')\n",
    "                cv2.imwrite(out_name,frame)\n",
    "        if not IN_COLAB & view :\n",
    "            cv2.imshow('video',frame)\n",
    "            k = cv2.waitKey(time_wait) & 0xff\n",
    "            if k == 27:\n",
    "                break;\n",
    "        if writer is not None:\n",
    "            writer.write(frame)\n",
    "        time_stamp += interval\n",
    "    if not IN_COLAB & view:\n",
    "        cv2.destroyAllWindows()\n",
    "    if writer is not None:\n",
    "        writer.release()\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "colab_type": "code",
    "id": "JZ3gHUd8KITL",
    "outputId": "7d17a3ca-8075-409c-eeb5-733071357ea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single image : ./img_interviewMovie.jpg detect only: True large_frame: True\n",
      "detect_face_locations True\n",
      "42 256 166 380\n",
      "35 104 160 228\n",
      "42 380 166 505\n",
      "63 477 187 601\n"
     ]
    }
   ],
   "source": [
    "#image_name=\"./test-data/IMG_6003.jpg\"\n",
    "#image_name=\"./test-data/IMG_6002.jpg\"\n",
    "image_name=os.path.join(DRIVE_ROOT,\"img_interviewMovie.jpg\")\n",
    "single_image(image_name,detect_only=True,debug=True,large_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wv743sfTKITQ",
    "outputId": "451867bc-2f4f-4cd8-b332-03e5f889ccf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interval:  0.04170833333333333 time_wait:  41\n",
      "1 00:18.435\n",
      "2 00:25.900\n",
      "3 00:42.709\n",
      "4 00:42.751\n",
      "5 00:42.792\n",
      "6 00:42.834\n",
      "7 00:42.876\n",
      "8 00:42.917\n",
      "9 00:42.959\n",
      "10 00:43.001\n",
      "11 00:43.042\n",
      "12 00:43.084\n",
      "13 00:43.126\n",
      "14 00:43.168\n",
      "15 00:43.209\n",
      "16 00:43.251\n",
      "17 00:43.293\n",
      "18 00:43.334\n",
      "19 00:43.418\n",
      "20 00:43.460\n",
      "21 00:43.501\n",
      "22 01:01.060\n",
      "23 01:01.186\n",
      "24 01:36.513\n",
      "25 01:37.555\n",
      "26 02:18.304\n",
      "27 02:18.596\n",
      "28 02:42.203\n",
      "29 02:45.248\n",
      "30 02:45.415\n",
      "31 02:45.498\n",
      "32 02:45.540\n",
      "33 02:45.582\n",
      "34 02:45.623\n",
      "35 02:45.665\n",
      "36 02:45.707\n",
      "37 02:45.748\n",
      "38 02:45.915\n",
      "39 03:13.735\n",
      "40 03:14.027\n",
      "41 03:14.068\n",
      "42 03:14.110\n",
      "43 03:21.326\n",
      "44 03:39.761\n",
      "45 03:42.597\n",
      "46 03:42.680\n",
      "47 03:42.764\n",
      "48 03:49.771\n",
      "49 03:49.812\n",
      "50 03:49.854\n",
      "51 03:50.146\n",
      "52 03:50.188\n",
      "53 03:56.235\n",
      "54 03:56.277\n",
      "55 04:04.160\n",
      "56 04:04.452\n",
      "57 04:04.535\n",
      "58 04:04.577\n",
      "59 04:04.619\n",
      "60 04:04.661\n",
      "61 04:04.702\n",
      "62 04:04.744\n",
      "63 04:04.786\n",
      "64 04:04.827\n",
      "65 04:04.869\n",
      "66 04:04.911\n",
      "67 04:04.953\n",
      "68 04:04.994\n",
      "69 04:05.036\n",
      "70 04:05.078\n",
      "71 04:05.119\n",
      "72 04:05.161\n",
      "73 04:05.203\n",
      "74 04:05.244\n",
      "75 04:05.286\n",
      "76 04:05.328\n",
      "77 04:05.370\n",
      "78 04:05.411\n",
      "79 04:05.453\n",
      "80 04:26.432\n",
      "81 04:27.684\n",
      "82 04:27.725\n",
      "83 04:27.767\n",
      "84 04:27.809\n",
      "85 04:27.850\n",
      "86 04:27.892\n",
      "87 05:14.772\n",
      "88 05:47.388\n",
      "89 05:47.472\n",
      "90 05:50.058\n",
      "91 05:50.099\n",
      "92 05:51.100\n",
      "93 05:55.938\n",
      "94 05:56.814\n",
      "95 05:56.856\n",
      "96 05:56.898\n",
      "97 06:19.379\n",
      "98 06:23.674\n",
      "99 06:23.716\n",
      "100 06:23.758\n",
      "101 06:45.154\n",
      "102 06:45.613\n",
      "103 06:45.696\n",
      "104 06:46.239\n",
      "105 06:57.041\n",
      "106 06:57.083\n",
      "107 07:05.925\n",
      "elapsed time:  32:32.611\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# name='gassou_15sec_small'\n",
    "# name='gassou_full_small'\n",
    "name='gassou_full_large'\n",
    "video_name=os.path.join(DRIVE_ROOT,name+'.mp4')\n",
    "out_name = name+'.avi'\n",
    "start = time.time()\n",
    "video_proc(video_name, output=out_name, capture=True, detect_only=False, view=True)\n",
    "elapsed_time=time.time() - start\n",
    "print('elapsed time: ',format_time(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "colab_type": "code",
    "id": "-T51alOLKITU",
    "outputId": "6856e471-dd1f-4287-85d4-0c20509a2fb2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('::ffff:127.0.0.1', 53990, 0, 0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 320, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 351, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 364, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 724, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/lib/python3.6/http/server.py\", line 418, in handle\n",
      "    self.handle_one_request()\n",
      "  File \"/usr/lib/python3.6/http/server.py\", line 406, in handle_one_request\n",
      "    method()\n",
      "  File \"/usr/lib/python3.6/http/server.py\", line 639, in do_GET\n",
      "    self.copyfile(f, self.wfile)\n",
      "  File \"/usr/lib/python3.6/http/server.py\", line 800, in copyfile\n",
      "    shutil.copyfileobj(source, outputfile)\n",
      "  File \"/usr/lib/python3.6/shutil.py\", line 82, in copyfileobj\n",
      "    fdst.write(buf)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 803, in write\n",
      "    self._sock.sendall(b)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "  file_name = os.path.join(OUT_DIR,out_name)\n",
    "  from google.colab import files\n",
    "  files.download(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCsQEYbvKITY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "face_dlib.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
