{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    %matplotlib inline\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    DRIVE_ROOT='/content/gdrive/My Drive/opencv/'\n",
    "except:\n",
    "    IN_COLAB =False\n",
    "    %matplotlib notebook  \n",
    "    DRIVE_ROOT='./'\n",
    "face_dir = os.path.join(DRIVE_ROOT,'known_face')\n",
    "OUT_DIR =os.path.join(DRIVE_ROOT,'output')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition part\n",
    "face_dir = os.path.join(DRIVE_ROOT,'known_face')\n",
    "OUT_DIR =os.path.join(DRIVE_ROOT,'output')\n",
    "\n",
    "# my son\n",
    "son_image = face_recognition.load_image_file('./training-data/s1/1.JPG')\n",
    "son_face_encoding = face_recognition.face_encodings(son_image)[0]\n",
    "\n",
    "# suzu\n",
    "suzu_image = face_recognition.load_image_file('./training-data/s4/7.jpg')\n",
    "suzu_face_encodeing = face_recognition.face_encodings(suzu_image)[0]\n",
    "\n",
    "# shishamo\n",
    "asa_image = face_recognition.load_image_file('./training-data/s5/2.jpg')\n",
    "asa_face_encodeing = face_recognition.face_encodings(asa_image)[0]\n",
    "\n",
    "known_face_encodings = [\n",
    "    son_face_encoding,\n",
    "    suzu_face_encodeing,\n",
    "    asa_face_encodeing\n",
    "]\n",
    "known_face_names =[\n",
    "    \"Toma\",\n",
    "    \"Suzu\",\n",
    "    \"Asako\"\n",
    "]\n",
    "\n",
    "#image=cv2.imread(\"img_interviewMovie.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asako\n",
      "ClassMate1\n",
      "ClassMate2\n",
      "Girl1\n",
      "Suzu\n",
      "Toma\n"
     ]
    }
   ],
   "source": [
    "known_face_encodings=[]\n",
    "known_face_names=[]\n",
    "subject_image_names=os.listdir(face_dir)\n",
    "for image_name in subject_image_names:\n",
    "    if image_name.startswith(\".\"):\n",
    "        continue\n",
    "    name=os.path.splitext(image_name)[0];\n",
    "    image_path = os.path.join(face_dir,image_name)\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    face_encoding = face_recognition.face_encodings(image)[0]\n",
    "    known_face_encodings.append(face_encoding)\n",
    "    known_face_names.append(name)\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single frame recognition\n",
    "def recognize_face(frame,do_scale=False,threshold=0.5,debug=False):\n",
    "    face_locations=[]\n",
    "    face_encodings=[]\n",
    "    face_names=[]\n",
    "    \n",
    "    if do_scale:\n",
    "        # resize frame to 1/4 size for faster processing\n",
    "        small_frame = cv2.resize(frame, (0,0), fx=0.25, fy=0.25)\n",
    "    else:\n",
    "        small_frame = frame\n",
    "    result=False   \n",
    "    # convert the image from BGR color to RGB color\n",
    "    rgb_small_frame = small_frame[:,:,::-1]\n",
    "    \n",
    "    # find all the faces and face encodings in the frame\n",
    "    face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "    #if debug:\n",
    "        #print(face_locations)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_small_frame,face_locations)\n",
    "    result=False\n",
    "    for face_encoding in face_encodings:\n",
    "        # see if the face is a match for the known face(s)\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        name = 'Unknown'\n",
    "        \n",
    "        # use the known face with the smallest distance\n",
    "        face_distance = face_recognition.face_distance(known_face_encodings,face_encoding)\n",
    "        best_match_index = np.argmin(face_distance)\n",
    "        if matches[best_match_index]:\n",
    "            if face_distance[best_match_index]<threshold:\n",
    "                name = known_face_names[best_match_index]\n",
    "            else:\n",
    "                name = '?'+known_face_names[best_match_index]+'?'\n",
    "            if debug:\n",
    "                print(name,face_distance)\n",
    "        if name == 'Toma':\n",
    "            result=True\n",
    "        face_names.append(name)\n",
    "    \n",
    "    #display result\n",
    "    for(top,right,bottom,left),name in zip(face_locations,face_names):\n",
    "        #scale back up face locations since the frame detected in was scaled to 1/4 size\n",
    "        if do_scale:\n",
    "            top *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "        \n",
    "        #draw a box around the face\n",
    "        cv2.rectangle(frame, (left,top), (right,bottom), (0,0,255),2)\n",
    "        \n",
    "        # draw a label with a name below the face\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        font_scale = 1.2\n",
    "        thickness = 2\n",
    "        margin=1\n",
    "        \n",
    "        size = cv2.getTextSize(name, font, font_scale, thickness)\n",
    "        text_width = size[0][0]\n",
    "        text_height = size[0][1]\n",
    "        \n",
    "        cv2.rectangle(frame, (left, bottom), (left+text_width+margin, bottom+text_height+margin), (0, 0, 255), cv2.FILLED)\n",
    "        cv2.putText(frame, name, (left,bottom + text_height), font,font_scale, (255,255,255), thickness)\n",
    "    return result,frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect face locations        \n",
    "def detect_face_locations(image,do_gray=False,do_scale=False):\n",
    "    if do_scale:\n",
    "        small_frame = cv2.resize(image, (0,0), fx=0.25, fy=0.25)\n",
    "    else:\n",
    "        small_frame = image\n",
    "    if do_gray:\n",
    "        gray = cv2.cvtColor(small_frame,cv2.COLOR_BGR2RGB)\n",
    "        rgb_frame = gray[:,:,::-1]\n",
    "    else:\n",
    "        rgb_frame=small_frame[:,:,::-1]\n",
    "\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    for face_location in face_locations:\n",
    "        (top,right,bottom,left)=face_location;\n",
    "        if do_scale:\n",
    "            top *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "\n",
    "        cv2.rectangle(image, (left,top), (right,bottom), (0,0,255),2)\n",
    "        #plt.plot(face_location[1],face_location[0],'bo')\n",
    "        #plt.plot(face_location[1],face_location[2],'bo')\n",
    "        #plt.plot(face_location[3],face_location[2],'bo')\n",
    "        #plt.plot(face_location[3],face_location[0],'bo')\n",
    "        #plt.show()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test functions\n",
    "# format time(second) as HH:MM:ss.mmm\n",
    "def format_time(sec):\n",
    "    msec = (int)(sec * 1000.)\n",
    "    s, ms = divmod(msec, 1000)\n",
    "    m, s =divmod(s,60)\n",
    "    return '{:02d}:{:02d}.{:03d}'.format(m,s,ms)\n",
    "\n",
    "def format_time_forfile(sec):\n",
    "    msec = (int)(sec * 1000.)\n",
    "    s, ms = divmod(msec, 1000)\n",
    "    m, s =divmod(s,60)\n",
    "    return '{:02d}m{:02d}s{:03d}ms'.format(m,s,ms)\n",
    "\n",
    "# single image\n",
    "def single_image(filename,detect_only=False,debug=False):\n",
    "#image=cv2.imread(\"img_interviewMovie.jpg\")\n",
    "    image=cv2.imread(filename)\n",
    "    if detect_only:\n",
    "        image=detect_face_locations(image)\n",
    "    else:\n",
    "        ret,image=recognize_face(image,debug=debug)\n",
    "    cv2.imshow(\"sigle test\",image)\n",
    "    if cv2.waitKey(0) & 0xFF:\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "def getInterval(fps):\n",
    "    interval =1.0/fps\n",
    "    time_wait = (int)(interval * 1000.0)\n",
    "    print('interval: ',interval,'time_wait: ',time_wait)\n",
    "    return interval,time_wait\n",
    "\n",
    "def video_proc(filename,output=None,capture=False,detect_only=False,no_wait=False,view=True):\n",
    "    pre = os.path.splitext(os.path.basename(filename))[0]\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    interval,time_wait = getInterval(fps)\n",
    "    time_stamp=0.0\n",
    "    frame_count=0\n",
    "    if no_wait:\n",
    "        time_wait=1\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    font_scale = 1.2\n",
    "    thickness = 2\n",
    "    margin=1\n",
    "    size = cv2.getTextSize(name, font, font_scale, thickness)\n",
    "    text_width = size[0][0]\n",
    "    text_height = size[0][1]\n",
    "    \n",
    "    # VideoWriter を作成する。\n",
    "    if output is not None:\n",
    "        if IN_COLAB:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "        else:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "        writer = cv2.VideoWriter(os.path.join(OUT_DIR,output), fourcc, fps, (width, height))\n",
    "    else:\n",
    "        writer = None\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "        if not ret:\n",
    "            cap.release()\n",
    "            break\n",
    "        frame_count += 1\n",
    "        if detect_only:\n",
    "            frame=detect_face_locations(frame)\n",
    "        else:\n",
    "            result,frame=recognize_face(frame)\n",
    "        cv2.putText(frame,format_time(time_stamp),(margin,margin+text_height),font,font_scale,(0,0,255),thickness)\n",
    "        if result:\n",
    "            print(format_time(time_stamp))\n",
    "            if capture:\n",
    "                out_name=os.path.join(OUT_DIR,pre+'_'+format_time_forfile(time_stamp)+'.png')\n",
    "                cv2.imwrite(out_name,frame)\n",
    "        if not IN_COLAB & view :\n",
    "            cv2.imshow('video',frame)\n",
    "            k = cv2.waitKey(time_wait) & 0xff\n",
    "            if k == 27:\n",
    "                break;\n",
    "        if writer is not None:\n",
    "            writer.write(frame)\n",
    "        time_stamp += interval\n",
    "    if not IN_COLAB & view:\n",
    "        cv2.destroyAllWindows()\n",
    "    if writer is not None:\n",
    "        writer.release()\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asako [0.32210644 0.61008718 0.51960748 0.51952807 0.54189701 0.52746794]\n",
      "ClassMate2 [0.60653735 0.56548027 0.46163067 0.46639278 0.6687554  0.65538055]\n",
      "Suzu [0.52390318 0.66028424 0.64709136 0.57801626 0.45595882 0.69426692]\n",
      "?Asako? [0.57083035 0.59946105 0.64740449 0.6142347  0.57324467 0.65324169]\n"
     ]
    }
   ],
   "source": [
    "#image_name=\"./test-data/IMG_6003.jpg\"\n",
    "#image_name=\"./test-data/IMG_6002.jpg\"\n",
    "image_name=\"./img_interviewMovie.jpg\"\n",
    "single_image(image_name,detect_only=False,debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interval:  0.04170833333333333 time_wait:  41\n",
      "00:07.006\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "video_name=os.path.join(DRIVE_ROOT,\"gassou_15sec_small.mp4\")\n",
    "start = time.time()\n",
    "video_proc(video_name, output='15S.avi', capture=True, detect_only=False, view=True)\n",
    "elapsed_time=time.time() - start\n",
    "print('elapsed time: ',format_time(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gassou_15sec_small'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(video_name)\n",
    "os.path.splitext(os.path.basename(video_name))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
